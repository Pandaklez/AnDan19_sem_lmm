---
title: "Семинар по смешанным моделям"
author: "Anna Klezovich"
date: '31.07.2019'
output:
    html_document:
        toc: true
        toc_float: true
        toc_depth: 2
---

Импортируем все нужные пакеты
```{r, echo=FALSE}
library(mlmRev)
library(lme4)
library(ggplot2)
library(lmtest)
library(tidyverse)
```

## Politeness
```{r}
polite <- read.csv("http://www.bodowinter.com/tutorial/politeness_data.csv")
head(polite)
str(polite)
```

```{r}
ggplot(polite, aes(x = factor(scenario), y = frequency, fill = factor(attitude)))+geom_boxplot()
```

Визуализируем переменные, которые мы хотим считать за рандомные эффекты
```{r}
ggplot(polite, aes(x=frequency, fill=subject)) +
geom_density(alpha=0.4)+facet_grid(gender ~ .)
```

```{r}
fit_1 <- lmer(frequency ~ attitude + (1|subject) + (1|scenario), polite)
summary(fit_1)
```

А что будет, если мы включим пол в основные эффекты?
```{r}
fit_2 <- lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), polite)
summary(fit_2)
```

Да ничего не будет вообще-то. Как же тогда определять какие эффекты фиксированные, а какие - случайные?

Определения фиксированных и случайных эффектов из разных умных книжек:

1. Fixed effects are constant across individuals, and random effects vary. (Kreft & de Leeuw 1998)

2. Effects are fixed if they are interesting in themselves or random if there is interest in the underlying population. (Searle, Casella & McCulloch 1992)

3. When a sample exhausts the population, the corresponding variable is fixed; when the sample is a small (i.e., negligible) part of the population the corresponding variable is random (Green & Tukey 1960)

4. Fixed effects are estimated using least squares (or, more generally, maximum likelihood) and random effects are estimated with **shrinkage** (Snijders and Bosker 1999)

Какая из этих моделей лучше?
```{r}
AIC(fit_1)
AIC(fit_2)
```

Проинтерпретируйте результаты лучшей модели способами, которые мы обсудили ранее.

## Speed dating
```{r}
load('speed_dating.RData')
head(speed_dating)
#str(speed_dating)
#summary(speed_dating)
```

Подготовим данные - уже не надо, там есть дублированные переменные, которые scaled
```{r}
# First, turn numeric to factors where needed
#speed_dating$partner_race <- as.factor(speed_dating$partner_race)
#speed_dating$attractive <- as.factor(speed_dating$attractive)
#speed_dating$sincere <- as.factor(speed_dating$sincere)
#speed_dating$intelligent <- as.factor(speed_dating$intelligent)
#speed_dating$fun <- as.factor(speed_dating$fun)
#speed_dating$ambitious <- as.factor(speed_dating$ambitious)
#speed_dating$shared_interests <- #as.factor(speed_dating$shared_interests)

#str(speed_dating)
```

Проверим на мультиколлинеарность. Ну вдруг привлекательность партнера зависит от того, насколько хорошее у партнера чувство юмора или высокий интеллект
```{r}
newvars <- c("attractive_sc", "sincere_sc", "ambitious_sc", "fun_sc", "shared_interests_sc")
short_sd <- speed_dating[newvars]
pairs(short_sd)
# тут всё ок
```

Попытаемся зафитить модель

```{r}
fit1 = glmer(decision ~ sex + samerace + attractive_sc + sincere_sc
                 + intelligent_sc 
                 + (1|iid), data=speed_dating, family=binomial)
summary(fit1, correlation=F)
```

```{r}
fit2 <- glmer(decision ~ intelligent + (1|wave:iid) + (1|sex),
                 data=speed_dating, family=binomial)
summary(fit2, correlation=F)
```

```{r}
fit1 <- glmer(decision ~ sex + fun_sc + attractive_sc + sincere_sc
                 + intelligent_sc 
                 + (1|iid), data=speed_dating, family=binomial)
summary(fit1, correlation=F)
```

```{r}
fit1 <- glmer(decision ~ sex + samerace + fun_sc + ambitious_sc + attractive_sc + sincere_sc
                 + intelligent_sc 
                 + (1|iid), data=speed_dating, family=binomial)
fit2 <- glmer(decision ~ sex + samerace + fun_sc + ambitious_sc + attractive_sc + sincere_sc
                 + (1|iid), data=speed_dating, family=binomial)
fit3 <- glmer(decision ~ sex + samerace + fun_sc + ambitious_sc + attractive_sc + (1|iid), data=speed_dating, family=binomial)
fit4 <- glmer(decision ~ sex + samerace + fun_sc + ambitious_sc + (1|iid), data=speed_dating, family=binomial)
fit5 <- glmer(decision ~ sex + samerace + (1|iid), data=speed_dating, family=binomial)
```

```{r}
#anova(fit4, fit5)
```
Так-так, проблемка

```{r}
sd <- speed_dating[!is.na(speed_dating$intelligent_sc),]
#summary(sd)

sd <- sd[!is.na(sd$sincere_sc),]
summary(sd)
```

```{r}
fit0 <- glmer(decision ~ sex + (1|iid), data=sd, family=binomial)
fit1 <- glmer(decision ~ sex + samerace + (1|iid), data=sd, family=binomial)
fit2 <- glmer(decision ~ sex + samerace + sincere_sc + (1|iid), data=sd, family=binomial)
fit3 <- glmer(decision ~ sex + samerace + sincere_sc + intelligent_sc  + (1|iid), data=sd, family=binomial)
```

```{r}
anova(fit3, fit2, fit1, fit0)
```

```{r}
summary(fit3)
```

Поищем случайные эффекты.
Вроде есть какой-то эффект у wave случайный
```{r}
ggplot(speed_dating, aes(x=factor(decision), fill=factor(wave))) +
geom_density(alpha=0.2)
```

```{r}
fit_r <- glmer(decision ~  sex + samerace + sincere_sc + intelligent_sc + (1|wave:iid),
                 data=sd, family=binomial)
summary(fit_r, correlation=F)

fit3 <- glmer(decision ~ sex + samerace + sincere_sc + intelligent_sc  + (1|iid), data=sd, family=binomial)
```

```{r}
anova(fit3, fit_r)
```

```{r}
library(stargazer)
stargazer(fit3, type = "text",
          digits = 3,
          star.cutoffs = c(0.05, 0.01, 0.001),
          digit.separator = "")
```

## Uncorrelated slope and intercept + model comparison

Вот какие-то сгенерированные данные.
```{r}
set.seed(22)
Ngroups = 50
NperGroup = 3
N = Ngroups*NperGroup
groups = factor(rep(1:Ngroups, each=NperGroup))
re_int = rnorm(Ngroups, sd=.75)
re_slope = rnorm(Ngroups, sd=.25)
e = rnorm(N, sd=.25)
x = rnorm(N)
y = (2 + re_int[groups]) + (.5 + re_slope[groups])*x + e

d = data.frame(x, y, groups)
```

Сравним, какая из двух моделей лучше описывает наши искусственные данные. 
```{r}
model_ints_only = lmer(y ~ x + (1|groups), REML=F, data=d)
model_with_slopes = lmer(y ~ x + (1|groups) + (0 + x|groups), REML=F, data=d)
anova(model_ints_only, model_with_slopes)

```

На самом деле, датасеты, в которых slope и intercept нескоррелированы практически не встречаются в реальной жизни.

## Пример из жизни лингвиста

Это задание на то, чтобы найти ошибку в исследовании наивного третьекурсника-лингвиста (меня) [А ещё, конечно же, на интерпретацию glmer]

Итак, мы хотим узнать, как порядок слов в именной группе относительно существительного зависит от типа модификатора, который при нём используется. (Звучит, максимально скучно, но это данные про русский жестовый язык, что сразу же делает эту задачу интереснее))

```{r}
adj<-read.delim("more_rows_second.csv")

head(adj)
```

```{r}
#then I turn the variables in question into factors because they are automatically recognized as integers
adj$modifiers<-as.factor(adj$modifiers)
adj$position<-as.factor(adj$Annotation)
colnames(adj)[2]<-"signer" #change the name of the column to a less confusing one
adj <- adj[c("modifiers", "position", "signer")]
```

```{r}
#Let's first see what the distribution is across the two factors
tab<-table(adj$position, adj$modifiers)
head(tab)
```

```{r}
colnames(tab)<-c("post", "pre")
rownames(tab)<-c("more", "one")
prop_tab <- prop.table(tab, margin = 1)
prop_tab
```
О чем нам это говорит? В обоих случаях и с одинарным модификатором, и с несколькими модификаторами, видна склонность к препозиции, но это склонность немного сильнее для одинарных модификаторов.

```{r}
#then I set up contrasts so that one modifier will be coded as 1/2, and more than 1 modifier as -1/2.
contrast<-rbind(-1/2,1/2) # 0 many 1 one
colnames(contrast)<-c("+1-many")
contrasts(adj$modifiers)<-contrast
contrasts(adj$modifiers)
```

```{r}
model<-glmer(formula = position ~ modifiers + (1+modifiers|signer), data=adj, family=binomial)
summary(model)
```

The model shows that overall preposition is significantly more likely (exp(0.75)=2.117 times more likely)
The model also shows that the odds of getting preposition is significantly more likely with a signle modifier than with plural modifiers (exp(0.9111)=2.487057 times more likely)

```{r}
model2<-glmer(formula = position ~ modifiers + (1|signer), data=adj, family=binomial)
summary(model2)
```

```{r}
anova(model2, model) # model is better LogLik closer to zero, AIC is smaller, stastically different from model2
```

"The model shows that overall the
preposition is 2.13 (exp(0.7557)) times more likely than the postposition regardless of the number
of modifiers by noun. In addition to that, the model shows that the preposition is 2.23 (exp(0.7998))
times more likely with a single modifier than with multiple modifiers."

Что не так? И как правильно?

## References

1. stepik Основы статистики. Часть 3.
2. Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables.
3.
